{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dropout ,Activation,AveragePooling2D, normalization,Convolution2D,MaxPooling2D\n",
    "from keras.layers import Dense, Flatten, Reshape, Input\n",
    "from keras.layers.merge import add\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.read_csv('/home/vasu/all_projects/ML/MNIST/mnist_kaggle/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(x)\n",
    "x = X[:,1:]\n",
    "y = X[:,0]\n",
    "print x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.reshape((X.shape[0], 28, 28,1))\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 26, 26, 32)    320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 26, 26, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 26, 26, 32)    9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 26, 26, 32)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 26, 26, 32)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 26, 26, 32)    9248        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 26, 26, 32)    0           conv2d_1[0][0]                   \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 24, 24, 16)    4624        add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 24, 24, 16)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 24, 24, 16)    2320        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 24, 24, 16)    0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 24, 24, 16)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 24, 24, 16)    2320        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 24, 24, 16)    0           conv2d_4[0][0]                   \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 22, 22, 8)     1160        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 22, 22, 8)     0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 11, 11, 8)     0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 968)           0           max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            31008       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            330         activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 10)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 60,578\n",
      "Trainable params: 60,578\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(28,28,1))\n",
    "x1 = Convolution2D( 32,(3,3))(inp)\n",
    "\n",
    "r1_a1 = Activation('relu')(x1)\n",
    "r1_w1 = Convolution2D(32,( 3,3),padding='same')(r1_a1)\n",
    "r1_a2 = Activation('relu')(r1_w1)\n",
    "r1_d1 = Dropout(0.2)(r1_a2)\n",
    "r1_w2 = Convolution2D(32,( 3,3),padding='same')(r1_d1)\n",
    "out1 = add([x1, r1_w2])\n",
    "\n",
    "x2 = Convolution2D(16,( 3,3))(out1)\n",
    "\n",
    "r2_a1 = Activation('relu')(x2)\n",
    "r2_w1 = Convolution2D(16,( 3,3),padding='same')(r2_a1)\n",
    "r2_a2 = Activation('relu')(r2_w1)\n",
    "r2_d1 = Dropout(0.2)(r2_a2)\n",
    "r2_w2 = Convolution2D(16,( 3,3),padding='same')(r2_d1)\n",
    "out2 = add([x2, r2_w2])\n",
    "\n",
    "x3 = Convolution2D(8,( 3,3))(out2)\n",
    "acti = Activation('relu')(x3)\n",
    "av_pool = MaxPooling2D((2,2))((acti))\n",
    "f1 = Flatten()(av_pool)\n",
    "fc1 = Dense(32)(f1)\n",
    "a1 = Activation('relu')(fc1)\n",
    "fc3 = Dense(10)(a1)\n",
    "a3 = Activation('softmax')(fc3)\n",
    "\n",
    "model = Model(outputs=a3, inputs=inp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 144s - loss: 0.4299 - acc: 0.8648 - val_loss: 0.1331 - val_acc: 0.9586\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.1131 - acc: 0.9668 - val_loss: 0.0805 - val_acc: 0.9749\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0708 - val_acc: 0.9762\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0620 - acc: 0.9808 - val_loss: 0.0592 - val_acc: 0.9821\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0497 - acc: 0.9843 - val_loss: 0.0586 - val_acc: 0.9813\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0437 - acc: 0.9861 - val_loss: 0.0647 - val_acc: 0.9813\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0377 - acc: 0.9882 - val_loss: 0.0585 - val_acc: 0.9827\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 135s - loss: 0.0363 - acc: 0.9884 - val_loss: 0.0495 - val_acc: 0.9846\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 136s - loss: 0.0309 - acc: 0.9902 - val_loss: 0.0468 - val_acc: 0.9862\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 138s - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0654 - val_acc: 0.9814\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 154s - loss: 0.0249 - acc: 0.9915 - val_loss: 0.0482 - val_acc: 0.9867\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 154s - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0536 - val_acc: 0.9855\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 154s - loss: 0.0178 - acc: 0.9940 - val_loss: 0.0517 - val_acc: 0.9856\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 156s - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0517 - val_acc: 0.9870\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 154s - loss: 0.0164 - acc: 0.9940 - val_loss: 0.0584 - val_acc: 0.9862\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 157s - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0557 - val_acc: 0.9856\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 154s - loss: 0.0139 - acc: 0.9951 - val_loss: 0.0559 - val_acc: 0.9868\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 157s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0559 - val_acc: 0.9854\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 156s - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0512 - val_acc: 0.9876\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 155s - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0600 - val_acc: 0.9854\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y,epochs = 20,shuffle=True,batch_size=256,validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde062695d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhND/B/VZdCeP7GsSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde09b77110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
